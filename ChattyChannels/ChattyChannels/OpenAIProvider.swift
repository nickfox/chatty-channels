// ChattyChannels/ChattyChannels/OpenAIProvider.swift

import Foundation
import os.log

// MARK: - OpenAI DTOs (Specific to this provider)

/// Represents a single message in a chat conversation, formatted for the OpenAI API.
///
/// Each message has a `role` (system, user, or assistant) and `content` (the text of the message).
private struct OAChatMessage: Codable {
    /// The role of the entity sending the message.
    /// Common values are "system", "user", or "assistant".
    let role: String
    /// The textual content of the message.
    let content: String
}

/// The request body structure for the OpenAI Chat Completions API.
///
/// It includes the model to be used and an array of ``OAChatMessage`` objects
/// representing the conversation history.
private struct OAChatRequest: Encodable {
    /// The identifier of the OpenAI model to use for generating the chat completion
    /// (e.g., "gpt-4o-mini", "gpt-3.5-turbo").
    let model: String
    /// An array of ``OAChatMessage`` objects, forming the conversation context.
    let messages: [OAChatMessage]
    // Future enhancements could include parameters like temperature, max_tokens, etc.
}

/// The response structure from the OpenAI Chat Completions API.
///
/// It primarily contains an array of `Choice` objects, from which the assistant's
/// message content is extracted.
private struct OAChatResponse: Decodable {
    /// Represents one of the completion choices returned by the API.
    struct Choice: Decodable {
        /// Contains the actual message generated by the assistant.
        struct ChoiceMessage: Decodable {
            /// The textual content of the assistant's message.
            let content: String
        }
        /// The assistant's message within this choice.
        let message: ChoiceMessage
        // let finish_reason: String? // Could be useful for more detailed response handling.
    }
    /// An array of completion choices. Typically, for chat completions, one choice is expected.
    let choices: [Choice]
    // let usage: UsageStats? // Could be added to monitor token usage.
}

// Example for UsageStats if needed in the future:
// /// Statistics about token usage for the API request.
// private struct UsageStats: Decodable {
//     let prompt_tokens: Int
//     let completion_tokens: Int
//     let total_tokens: Int
// }

// MARK: - OpenAIProvider Implementation

/// An ``LLMProvider`` implementation for interacting with OpenAI's Chat Completion API.
///
/// This class handles the specifics of formatting requests for the OpenAI API,
/// sending them, and parsing the responses. It uses Bearer token authentication.
///
/// ## Configuration
/// The provider is initialized with an API key and an optional model name and endpoint URL.
/// If `modelName` is not provided, it defaults to `"gpt-4o-mini"`.
/// If `endpoint` is not provided, it defaults to `"https://api.openai.com/v1/chat/completions"`.
///
/// ## Topics
/// ### Initializers
/// - ``init(apiKey:modelName:endpoint:)``
/// ### Conforming to LLMProvider
/// - ``sendMessage(_:systemPrompt:)``
final class OpenAIProvider: LLMProvider {
    private let apiKey: String
    private let modelName: String
    private let endpointURL: URL
    private let logger: Logger
    private let urlSession: URLSession // Added URLSession property

    /// The default API endpoint for OpenAI chat completions.
    private static let defaultEndpoint = "https://api.openai.com/v1/chat/completions"
    /// The default model used if no specific model is requested during initialization.
    private static let defaultModel = "gpt-4o-mini"

    /// Initializes a new `OpenAIProvider`.
    /// - Parameters:
    ///   - apiKey: The API key for OpenAI.
    ///   - modelName: Optional. The specific OpenAI model to use (e.g., "gpt-4o-mini").
    ///                Defaults to ``defaultModel`` if `nil`.
    ///   - endpoint: Optional. A custom endpoint URL for the OpenAI API. Defaults to ``defaultEndpoint``.
    ///   - urlSession: Optional. The URLSession instance to use for network requests. Defaults to `URLSession.shared`.
    init(apiKey: String, modelName: String? = nil, endpoint: String? = nil, urlSession: URLSession = .shared) { // Designated initializer
        self.apiKey = apiKey
        self.modelName = modelName ?? OpenAIProvider.defaultModel
        self.urlSession = urlSession // Store the session
        
        let urlString = endpoint ?? OpenAIProvider.defaultEndpoint
        guard let url = URL(string: urlString) else {
            // This should ideally not happen with a default static string.
            // If it does, it's a critical configuration error.
            fatalError("Invalid OpenAI endpoint URL constructed: \(urlString). This indicates a programming error with the default URL string or a malformed custom endpoint.")
        }
        self.endpointURL = url
        
        self.logger = Logger(subsystem: Bundle.main.bundleIdentifier ?? "ChattyChannelsApp",
                             category: "OpenAIProvider")
        logger.info("OpenAIProvider initialized. Model: '\(self.modelName)', Endpoint: '\(self.endpointURL.absoluteString)'")
    }
    
    /// Required initializer for ``LLMProvider`` conformance. Uses `URLSession.shared`.
    convenience required init(apiKey: String, modelName: String?, endpoint: String?) {
        self.init(apiKey: apiKey, modelName: modelName, endpoint: endpoint, urlSession: .shared)
    }

    /// Sends a message to the OpenAI Chat Completion API.
    ///
    /// Constructs a request with the system prompt and user input, sends it to the
    /// configured OpenAI model and endpoint, and processes the response.
    ///
    /// - Parameters:
    ///   - input: The user's text message.
    ///   - systemPrompt: The system prompt to guide the AI's behavior.
    /// - Returns: The assistant's reply as a `String`.
    /// - Throws: A ``NetworkError`` if the request fails at any stage (encoding, network,
    ///           API error, decoding).
    func sendMessage(_ input: String, systemPrompt: String) async throws -> String {
        var request = URLRequest(url: endpointURL)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        let chatRequest = OAChatRequest(
            model: self.modelName,
            messages: [
                OAChatMessage(role: "system", content: systemPrompt),
                OAChatMessage(role: "user", content: input)
            ]
        )

        do {
            request.httpBody = try JSONEncoder().encode(chatRequest)
            // Sensitive data (full request body including prompts) logged at DEBUG level only.
            logger.debug("Sending request to OpenAI. Body: \(String(data: request.httpBody ?? Data(), encoding: .utf8) ?? "Could not decode body for logging")")
        } catch {
            logger.error("Failed to encode OpenAI request: \(error.localizedDescription)")
            throw NetworkError.requestFailed("Encoding request for OpenAI failed: \(error.localizedDescription)")
        }
        
        logger.info("ðŸ”¼ OpenAI: Sending to model '\(self.modelName)'. User input: \"\(input, privacy: .public)\"")

        do {
            // Use the injected urlSession instance
            let (data, response) = try await self.urlSession.data(for: request)

            guard let httpResponse = response as? HTTPURLResponse else {
                logger.error("No HTTPURLResponse received from OpenAI.")
                throw NetworkError.invalidResponse(0, "No HTTP response received from OpenAI.")
            }

            let rawResponseBody = String(data: data, encoding: .utf8) ?? "Â«empty or non-UTF8 response bodyÂ»"
            // Sensitive data (full response body) logged at DEBUG level only.
            logger.debug("OpenAI raw response. Status: \(httpResponse.statusCode). Body: \(rawResponseBody, privacy: .sensitive)")

            guard (200...299).contains(httpResponse.statusCode) else {
                logger.error("OpenAI API returned an error. Status: \(httpResponse.statusCode). Body: \(rawResponseBody)")
                throw NetworkError.invalidResponse(httpResponse.statusCode, "OpenAI API Error: \(rawResponseBody)")
            }

            let decodedResponse: OAChatResponse
            do {
                decodedResponse = try JSONDecoder().decode(OAChatResponse.self, from: data)
            } catch {
                logger.error("Failed to decode OpenAI JSON response: \(error.localizedDescription). Raw body for context: \(rawResponseBody)")
                throw NetworkError.decodingFailed("Decoding OpenAI JSON response failed: \(error.localizedDescription). Response: \(rawResponseBody)")
            }

            guard let replyContent = decodedResponse.choices.first?.message.content else {
                logger.error("No message content found in OpenAI response. Number of choices: \(decodedResponse.choices.count).")
                throw NetworkError.decodingFailed("No message content in OpenAI response. Check API response structure.")
            }
            
            let trimmedReply = replyContent.trimmingCharacters(in: .whitespacesAndNewlines)
            logger.info("ðŸ”½ OpenAI: Received reply from model '\(self.modelName)'. Assistant: \"\(trimmedReply, privacy: .public)\"")
            return trimmedReply

        } catch let error as NetworkError {
            // Logged at the point of throwing or in the calling function (NetworkService)
            throw error
        } catch let urlError as URLError {
            logger.error("OpenAI URLSession error: \(urlError.localizedDescription), Code: \(urlError.code.rawValue)")
            throw NetworkError.networkUnreachable("Network communication error with OpenAI: \(urlError.localizedDescription) (Code: \(urlError.code.rawValue))")
        } catch {
            logger.error("An unknown error occurred during the OpenAI request: \(error.localizedDescription)")
            throw NetworkError.requestFailed("An unknown error occurred with OpenAI: \(error.localizedDescription)")
        }
    }
}