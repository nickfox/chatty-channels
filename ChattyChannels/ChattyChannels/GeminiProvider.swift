// ChattyChannels/ChattyChannels/GeminiProvider.swift

import Foundation
import os.log

// MARK: - Gemini DTOs (Specific to this provider)

/// Defines the roles for messages in the Gemini API.
/// Gemini uses "user" for user messages and "model" for assistant/system messages within the content array.
private enum GeminiRole: String, Codable {
    /// Indicates a message from the user.
    case user
    /// Indicates a message from the model (assistant).
    case model
}

/// Represents a single part of a ``GeminiContent`` message, typically containing text.
private struct GeminiPart: Codable {
    /// The textual content of this part.
    let text: String
}

/// Represents a single piece of content in a Gemini API request or response,
/// associated with a role and containing one or more parts.
private struct GeminiContent: Codable {
    /// The role of the entity that produced this content (e.g., "user", "model").
    let role: String
    /// An array of ``GeminiPart`` objects that make up this content.
    let parts: [GeminiPart]
}

/// Defines safety settings for a Gemini API request, allowing control over content filtering.
private struct GeminiSafetySetting: Codable {
    /// The category of safety setting (e.g., "HARM_CATEGORY_HARASSMENT").
    let category: String
    /// The threshold for blocking content in this category (e.g., "BLOCK_MEDIUM_AND_ABOVE").
    let threshold: String
}

/// Defines generation configuration parameters for a Gemini API request.
private struct GeminiGenerationConfig: Codable {
    /// Controls randomness in token selection. Lower values make responses more deterministic.
    let temperature: Double?
    /// The cumulative probability cutoff for token selection.
    let topP: Double?
    /// The maximum number of tokens to consider when sampling.
    let topK: Int?
    /// The maximum number of tokens to generate in the response.
    let maxOutputTokens: Int?
}

/// The request body for the Gemini API's `generateContent` endpoint.
private struct GeminiGenerateContentRequest: Codable {
    /// An array of ``GeminiContent`` objects representing the conversation history and current prompt.
    let contents: [GeminiContent]
    /// Optional system-level instructions for guiding the model's behavior.
    /// Supported by newer models like Gemini 1.5 Pro.
    let systemInstruction: GeminiContent?
    /// Optional array of ``GeminiSafetySetting`` to configure content safety filters.
    let safetySettings: [GeminiSafetySetting]?
    /// Optional ``GeminiGenerationConfig`` to control aspects of the generation process.
    let generationConfig: GeminiGenerationConfig?

    init(contents: [GeminiContent], systemInstruction: GeminiContent? = nil, safetySettings: [GeminiSafetySetting]? = nil, generationConfig: GeminiGenerationConfig? = nil) {
        self.contents = contents
        self.systemInstruction = systemInstruction
        self.safetySettings = safetySettings
        self.generationConfig = generationConfig
    }
}

/// Represents a candidate response generated by the Gemini model.
private struct GeminiCandidate: Decodable {
    /// The content generated by the model for this candidate.
    struct CandidateContent: Decodable {
        /// An array of ``GeminiPart`` objects forming the model's response.
        let parts: [GeminiPart]
        /// The role associated with this content, typically "model".
        let role: String?
    }
    /// The actual content of the candidate response.
    let content: CandidateContent?
    /// The reason why the model stopped generating tokens (e.g., "STOP", "MAX_TOKENS").
    let finishReason: String?
    // let safetyRatings: [SafetyRating]? // Could be added for detailed safety feedback.
}

/// The response structure from the Gemini API's `generateContent` endpoint.
private struct GeminiGenerateContentResponse: Decodable {
    /// An array of ``GeminiCandidate`` objects, each representing a possible response from the model.
    /// Typically, one candidate is expected for non-streaming requests.
    let candidates: [GeminiCandidate]?
    // let promptFeedback: PromptFeedback? // Could be added for feedback on the prompt itself.
}


// MARK: - GeminiProvider Implementation

/// An ``LLMProvider`` implementation for interacting with Google's Gemini API.
///
/// This class handles the specifics of formatting requests for the Gemini API's
/// `generateContent` endpoint, sending them, and parsing the responses.
/// Authentication is handled by including the API key as a URL query parameter.
///
/// ## Configuration
/// The provider is initialized with an API key and an optional model name.
/// If `modelName` is not provided, it defaults to `"gemini-1.5-pro-latest"`.
/// The endpoint URL is constructed based on the model name.
///
/// ## System Prompt Handling
/// For models identified as "1.5-pro", it attempts to use the `systemInstruction` field.
/// For other models, it prepends the system prompt to the `contents` array,
/// including a priming message from the "model" role.
///
/// ## Topics
/// ### Initializers
/// - ``init(apiKey:modelName:endpoint:)``
/// ### Conforming to LLMProvider
/// - ``sendMessage(_:systemPrompt:)``
final class GeminiProvider: LLMProvider {
    private let apiKey: String
    private let modelName: String
    private let endpointURL: URL
    private let urlSession: URLSession // Added missing property
    private let logger: Logger

    /// The base URL for the Google AI Gemini API.
    private static let googleAIBaseURL = "https://generativelanguage.googleapis.com/v1beta/models"
    /// The default Gemini model used if no specific model is requested.
    private static let defaultModel = "gemini-1.5-pro-latest"

    /// Initializes a new `GeminiProvider`.
    /// - Parameters:
    ///   - apiKey: The API key for Google AI Studio / Gemini API.
    ///   - modelName: Optional. The specific Gemini model to use. Defaults to ``defaultModel``.
    ///   - endpoint: Ignored. Endpoint is derived from `modelName`.
    ///   - urlSession: Optional. The URLSession instance to use. Defaults to `URLSession.shared`.
    init(apiKey: String, modelName: String? = nil, endpoint: String? = nil, urlSession: URLSession = .shared) { // Designated initializer
        self.apiKey = apiKey
        self.modelName = modelName ?? GeminiProvider.defaultModel
        self.urlSession = urlSession // Store the session
        
        // Endpoint is constructed dynamically based on the model name.
        guard let url = URL(string: "\(GeminiProvider.googleAIBaseURL)/\(self.modelName):generateContent") else {
            // This should only fail if modelName results in an invalid URL segment.
            fatalError("Invalid Gemini endpoint URL constructed with model: \(self.modelName). Ensure model name is URL-safe.")
        }
        self.endpointURL = url
        
        self.logger = Logger(subsystem: Bundle.main.bundleIdentifier ?? "ChattyChannelsApp",
                             category: "GeminiProvider")
        logger.info("GeminiProvider initialized. Model: '\(self.modelName)', Endpoint: '\(self.endpointURL.absoluteString)'")
    }
    
    /// Required initializer for ``LLMProvider`` conformance. Uses `URLSession.shared`.
    convenience required init(apiKey: String, modelName: String?, endpoint: String?) {
        self.init(apiKey: apiKey, modelName: modelName, endpoint: endpoint, urlSession: .shared)
    }

    /// Sends a message to the Gemini API.
    ///
    /// Constructs a `generateContent` request, including handling of the system prompt
    /// based on the model name, and processes the response.
    ///
    /// - Parameters:
    ///   - input: The user's text message.
    ///   - systemPrompt: The system prompt to guide the AI's behavior.
    /// - Returns: The assistant's reply as a `String`.
    /// - Throws: A ``NetworkError`` if the request fails at any stage.
    func sendMessage(_ input: String, systemPrompt: String) async throws -> String {
        var urlComponents = URLComponents(url: self.endpointURL, resolvingAgainstBaseURL: false) // Added self.
        urlComponents?.queryItems = [URLQueryItem(name: "key", value: self.apiKey)] // Corrected: name is "key", value is self.apiKey

        guard let finalURL = urlComponents?.url else {
            self.logger.error("Failed to construct final Gemini URL with API key. Original endpoint: \(self.endpointURL.absoluteString)")
            throw NetworkError.invalidURL
        }

        var request = URLRequest(url: finalURL)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        let geminiRequest: GeminiGenerateContentRequest
        // Heuristic: Newer models like 1.5 Pro support the 'systemInstruction' field.
        // Older models or general 'gemini-pro' might require the system prompt to be part of the 'contents'.
        if self.modelName.contains("1.5-pro") || self.modelName.contains("1.5-flash") { // Check for models known to support systemInstruction. Added self.
             geminiRequest = GeminiGenerateContentRequest(
                contents: [GeminiContent(role: GeminiRole.user.rawValue, parts: [GeminiPart(text: input)])],
                // The 'systemInstruction' itself is a GeminiContent object.
                // Its role should be 'user' or 'model' as per API docs for this field. 'user' is often used.
                systemInstruction: GeminiContent(role: GeminiRole.user.rawValue, parts: [GeminiPart(text: systemPrompt)])
            )
            self.logger.debug("Using 'systemInstruction' field for Gemini model '\(self.modelName)'.")
        } else { // Fallback for models like 'gemini-pro' (non-1.5 versions)
            // For models not explicitly supporting 'systemInstruction', prepend the system prompt
            // as part of the conversation history. A common pattern is:
            // 1. User message (acting as system prompt)
            // 2. Model priming response (optional, but can help guide)
            // 3. Actual user message
            geminiRequest = GeminiGenerateContentRequest(
                contents: [
                    GeminiContent(role: GeminiRole.user.rawValue, parts: [GeminiPart(text: systemPrompt)]),
                    GeminiContent(role: GeminiRole.model.rawValue, parts: [GeminiPart(text: "Understood. I will follow these instructions.")]), // Simple priming
                    GeminiContent(role: GeminiRole.user.rawValue, parts: [GeminiPart(text: input)])
                ]
            )
            self.logger.debug("Prepending system prompt to 'contents' for Gemini model '\(self.modelName)'.")
        }

        do {
            request.httpBody = try JSONEncoder().encode(geminiRequest)
            self.logger.debug("Sending request to Gemini. Body: \(String(data: request.httpBody ?? Data(), encoding: .utf8) ?? "Could not decode body for logging")")
        } catch {
            self.logger.error("Failed to encode Gemini request: \(error.localizedDescription)")
            throw NetworkError.requestFailed("Encoding request for Gemini failed: \(error.localizedDescription)")
        }

        self.logger.info("ðŸ”¼ Gemini: Sending to model '\(self.modelName)'. User input: \"\(input, privacy: .public)\"")

        do {
            // Use the injected urlSession instance
            let (data, response) = try await self.urlSession.data(for: request)

            guard let httpResponse = response as? HTTPURLResponse else {
                self.logger.error("No HTTPURLResponse received from Gemini.")
                throw NetworkError.invalidResponse(0, "No HTTP response received from Gemini.")
            }
            
            let rawResponseBody = String(data: data, encoding: .utf8) ?? "Â«empty or non-UTF8 response bodyÂ»"
            self.logger.debug("Gemini raw response. Status: \(httpResponse.statusCode). Body: \(rawResponseBody, privacy: .sensitive)")

            guard (200...299).contains(httpResponse.statusCode) else {
                self.logger.error("Gemini API returned an error. Status: \(httpResponse.statusCode). Body: \(rawResponseBody)")
                throw NetworkError.invalidResponse(httpResponse.statusCode, "Gemini API Error: \(rawResponseBody)")
            }

            let decodedResponse: GeminiGenerateContentResponse
            do {
                decodedResponse = try JSONDecoder().decode(GeminiGenerateContentResponse.self, from: data)
            } catch {
                self.logger.error("Failed to decode Gemini JSON response: \(error.localizedDescription). Raw body for context: \(rawResponseBody)")
                throw NetworkError.decodingFailed("Decoding Gemini JSON response failed: \(error.localizedDescription). Response: \(rawResponseBody)")
            }

            guard let candidates = decodedResponse.candidates,
                  let firstCandidate = candidates.first,
                  let candidateContent = firstCandidate.content,
                  !candidateContent.parts.isEmpty else { // Check if parts array is not empty
                self.logger.error("No message content or parts found in Gemini response. Candidates count: \(decodedResponse.candidates?.count ?? 0).")
                throw NetworkError.decodingFailed("No message content or parts in Gemini response. Check API response structure.")
            }
            
            // Concatenate text from all parts in the candidate's content.
            let replyContent = candidateContent.parts.map { $0.text }.joined()

            let trimmedReply = replyContent.trimmingCharacters(in: .whitespacesAndNewlines)
            self.logger.info("ðŸ”½ Gemini: Received reply from model '\(self.modelName)'. Assistant: \"\(trimmedReply, privacy: .public)\"")
            return trimmedReply

        } catch let error as NetworkError {
            throw error
        } catch let urlError as URLError {
            self.logger.error("Gemini URLSession error: \(urlError.localizedDescription), Code: \(urlError.code.rawValue)")
            throw NetworkError.networkUnreachable("Network communication error with Gemini: \(urlError.localizedDescription) (Code: \(urlError.code.rawValue))")
        } catch {
            self.logger.error("An unknown error occurred during the Gemini request: \(error.localizedDescription)")
            throw NetworkError.requestFailed("An unknown error occurred with Gemini: \(error.localizedDescription)")
        }
    }
}